{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runs two basic convolutional networks on the pilot dataset.\n",
    "\n",
    "### Things to do next\n",
    "- Figure out how to do regression (see below).\n",
    "- ~~Figure out how to do multitask learning (i.e. try to predict the different reps and different genes).~~\n",
    "- ~~Run on the scale up dataset.~~\n",
    "- Read up on the \"Interpreting a DragoNN model using filter visualization\" and \"Interpreting data with a DragoNN model\" in the Dragonn tutorial.\n",
    "\n",
    "### Installing Dragonn\n",
    "- Clone from https://github.com/kundajelab/dragonn\n",
    "- ```python setup.py```\n",
    "    - I needed to ```brew install geos```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/Users/andrewlamb/anaconda/lib/python2.7/site-packages/Theano-0.8.2-py2.7.egg/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "from dragonn import models\n",
    "\n",
    "from collections import OrderedDict\n",
    "from pprint import pprint\n",
    "from warnings import warn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data.\n",
    "- Samples are sequences that will be one hot encoded\n",
    "- Try and predict the normalized values. **I couldn't figure out how to do regression with Dragonn, so I just rounded the values to 0 or 1 based on the median.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewlamb/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:21: UserWarning: Replacing 'N' bases in seq with 'A' in seq NNNNNNNNNGATCCCGCGGCCGTGTTTTCCTGGTGGCCCGGCCGTGCCTGAGGTTTCTCCCCGAGCCGCCGCCTCTGCGGGCTCCCGGGTGCCCTTGCCCTCACGGTCCCCGGCCCTCGCCCGTCTGTGCCCTCTTCCCCGCCCG.\n",
      "/Users/andrewlamb/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:21: UserWarning: Replacing 'N' bases in seq with 'A' in seq NNNNGATCCCGCGGCCGTGTTTTCCTGGTGGCCCGGCCGTGCCTGAGGTTTCTCCCCGAGCCGCCGCCTCTGCGGGCTCCCGGGTGCCCTTGCCCTCACGGTCCCCGGCCCTCGCCCGTCTGTGCCCTCTTCCCCGCCCGCCGCC.\n",
      "/Users/andrewlamb/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:21: UserWarning: Replacing 'N' bases in seq with 'A' in seq NNNNNNNNNNNNNNNNNNGAATTCAATGGAGTGGACTGGAGTGCTGTGGGGTGGAGTGGAATGGAGTGTAGTTGAATGGAGTGGAATGGAATGCGATGGAATGGAGTGGAGTTGAGCAGAGTGAAGTGGAAAGGTGTAGAATGGA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('H1hesc_1_0_0_chr20_30310735',\n",
      "  'GGGAGCCCAGAAGGCGACACAGGAATTGCGAAGCTCAGGAACCAGCCCCCTCGCTTGCTTCCTCCTCCATCGCCCGGATCGAGGGCGGCCGCTCCGCAGCCGCGGCCTCCTGCCACCCGGGAGCCCAGCCCCCTCTCTCTTGCAC'),\n",
      " ('H1hesc_1_0_1_chr20_30310735',\n",
      "  'CCCAGAAGGCGACACAGGAATTGCGAAGCTCAGGAACCAGCCCCCTCGCTTGCTTCCTCCTCCATCGCCCGGATCGAGGGCGGCCGCTCCGCAGCCGCGGCCTCCTGCCACCCGGGAGCCCAGCCCCCTCTCTCTTGCACGCCCC'),\n",
      " ('H1hesc_1_0_2_chr20_30310735',\n",
      "  'AAGGCGACACAGGAATTGCGAAGCTCAGGAACCAGCCCCCTCGCTTGCTTCCTCCTCCATCGCCCGGATCGAGGGCGGCCGCTCCGCAGCCGCGGCCTCCTGCCACCCGGGAGCCCAGCCCCCTCTCTCTTGCACGCCCCTTGGC'),\n",
      " ('H1hesc_1_0_3_chr20_30310735',\n",
      "  'GACACAGGAATTGCGAAGCTCAGGAACCAGCCCCCTCGCTTGCTTCCTCCTCCATCGCCCGGATCGAGGGCGGCCGCTCCGCAGCCGCGGCCTCCTGCCACCCGGGAGCCCAGCCCCCTCTCTCTTGCACGCCCCTTGGCTCTCC'),\n",
      " ('H1hesc_1_0_4_chr20_30310735',\n",
      "  'AGGAATTGCGAAGCTCAGGAACCAGCCCCCTCGCTTGCTTCCTCCTCCATCGCCCGGATCGAGGGCGGCCGCTCCGCAGCCGCGGCCTCCTGCCACCCGGGAGCCCAGCCCCCTCTCTCTTGCACGCCCCTTGGCTCTCCGCCTC')]\n",
      "487137 total sequences of length 145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewlamb/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:21: UserWarning: Replacing 'N' bases in seq with 'A' in seq NNNNNNNNNNNNNGAATTCAATGGAGTGGACTGGAGTGCTGTGGGGTGGAGTGGAATGGAGTGTAGTTGAATGGAGTGGAATGGAATGCGATGGAATGGAGTGGAGTTGAGCAGAGTGAAGTGGAAAGGTGTAGAATGGAATGGA.\n",
      "/Users/andrewlamb/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:21: UserWarning: Replacing 'N' bases in seq with 'A' in seq NNNNNNNNGAATTCAATGGAGTGGACTGGAGTGCTGTGGGGTGGAGTGGAATGGAGTGTAGTTGAATGGAGTGGAATGGAATGCGATGGAATGGAGTGGAGTTGAGCAGAGTGAAGTGGAAAGGTGTAGAATGGAATGGAATGGA.\n",
      "/Users/andrewlamb/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:21: UserWarning: Replacing 'N' bases in seq with 'A' in seq NNNGAATTCAATGGAGTGGACTGGAGTGCTGTGGGGTGGAGTGGAATGGAGTGTAGTTGAATGGAGTGGAATGGAATGCGATGGAATGGAGTGGAGTTGAGCAGAGTGAAGTGGAAAGGTGTAGAATGGAATGGAATGGAGTGGA.\n"
     ]
    }
   ],
   "source": [
    "key_to_seq = OrderedDict()\n",
    "\n",
    "with open(\"../data/Scaleup_counts_sequences/ScaleUpDesign1.sequences.txt\") as f:\n",
    "    for line in f:\n",
    "        key, seq = line.strip().split()\n",
    "        \n",
    "        # TODO: Figure out if this is an OK thing to do. 'N' basically means the \n",
    "        # sequencing software couldn't figure out what the base was...?\n",
    "        if \"N\" in seq:\n",
    "            warn(\"Replacing 'N' bases in seq with 'A' in seq {}.\".format(seq))\n",
    "            seq = seq.replace(\"N\", \"A\")\n",
    "        \n",
    "        assert key not in key_to_seq\n",
    "        key_to_seq[key] = seq\n",
    "        \n",
    "with open(\"../data/Scaleup_counts_sequences/ScaleUpDesign2.sequences.txt\") as f:\n",
    "    for line in f:\n",
    "        key, seq = line.strip().split()\n",
    "        \n",
    "        if \"N\" in seq:\n",
    "            warn(\"Replacing 'N' bases in seq with 'A' in seq {}.\".format(seq))\n",
    "            seq = seq.replace(\"N\", \"A\")\n",
    "        \n",
    "        assert key not in key_to_seq\n",
    "        key_to_seq[key] = seq\n",
    "        \n",
    "pprint(key_to_seq.items()[:5])\n",
    "\n",
    "print \"{} total sequences of length {}\".format(len(key_to_seq), len(key_to_seq.values()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from experiment ('HepG2', 'minP'):\n",
      "[('H1hesc_9_213_18_chr2_26895415', -4.259193703616347),\n",
      " ('K562_14_89_10_chr19_14848415', -2.293409418954255),\n",
      " ('H1hesc_8_354_3_chr5_174622815', -0.6748385255902782),\n",
      " ('H1hesc_5_1094_24_chr4_40311455', -0.1252866601459317),\n",
      " ('Huvec_12_379_1_chr14_67894115', -0.5824728799359882)]\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "cell_types =  [\"HepG2\", \"K562\"]\n",
    "promoters = [\"SV40P\", \"minP\"]\n",
    "design_names = [\"ScaleUpDesign1\", \"ScaleUpDesign2\"]\n",
    "\n",
    "for cell_type in cell_types:\n",
    "    for promoter in promoters:\n",
    "        experiment_key = (cell_type, promoter)\n",
    "\n",
    "        for design_name in design_names:\n",
    "            data[experiment_key] = {}\n",
    "\n",
    "            with open(\"../data/Scaleup_normalized/{}_{}_{}_mRNA_Rep1.normalized\".format(cell_type, design_name, promoter)) as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "\n",
    "                    key = parts[0]\n",
    "                    val = float(parts[1])\n",
    "                    if parts[2] == \"1\":\n",
    "                        data[experiment_key][key] = val\n",
    "\n",
    "            with open(\"../data/Scaleup_normalized/{}_{}_{}_mRNA_Rep2.normalized\".format(cell_type, design_name, promoter)) as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "\n",
    "                    key = parts[0]\n",
    "                    val = float(parts[1])\n",
    "                    if parts[2] == \"1\" and key in data[experiment_key]:\n",
    "                        data[experiment_key][key] = val\n",
    "            \n",
    "print \"Data from experiment {}:\".format(data.items()[0][0])\n",
    "pprint(data.items()[0][1].items()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# One hot encode DNA sequences the standard way.\n",
    "bases = ['A', 'T', 'C', 'G']\n",
    "\n",
    "def one_hot_encode_seq(seq):\n",
    "    result = np.zeros((len(bases), len(seq)))\n",
    "    \n",
    "    for i, base in enumerate(seq):\n",
    "        result[bases.index(base), i] = 1\n",
    "\n",
    "    return result\n",
    "\n",
    "def seqs_to_encoded_matrix(seqs):\n",
    "    # Wrangle the data into a shape that Dragonn wants.\n",
    "    result = np.concatenate(\n",
    "        map(one_hot_encode_seq, seqs)\n",
    "    ).reshape(\n",
    "        len(seqs), 1, len(bases), len(seqs[0])\n",
    "    )\n",
    "    \n",
    "    # Check we actually did the encoding right.\n",
    "    for i in range(len(seqs)):\n",
    "        for j in range(len(seqs[0])):\n",
    "            assert sum(result[i, 0, :, j]) == 1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We formulate this as a multi-task learning problem, where each cell type and promoter combo is a task, i.e. the tasks are \n",
    "- Some of the normalized scores are too noisy (as determined by the SHARPR software). For now, we only consider a sequence if it has a good measurement for all of the tasks\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129623 sequences have measurements for all tasks.\n"
     ]
    }
   ],
   "source": [
    "valid_keys = reduce(\n",
    "    lambda acc, d: acc.intersection(d.keys()), \n",
    "    data.values()[1:], \n",
    "    set(data.values()[0].keys())\n",
    ")\n",
    "\n",
    "print \"{} sequences have measurements for all tasks.\".format(len(valid_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = seqs_to_encoded_matrix([key_to_seq[key] for key in valid_keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129623, 1, 4, 145)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Just round to the median, to make this a classification task for now.\n",
    "experiment_labels = []\n",
    "for experiment_key, key_to_normalized in data.items():\n",
    "    \n",
    "    filtered_normalized = [key_to_normalized[key] for key in valid_keys]\n",
    "    \n",
    "    median = np.median(filtered_normalized)\n",
    "    experiment_labels.append(\n",
    "        np.array(map(lambda val: val > median, filtered_normalized)).reshape(-1, 1)\n",
    "    )\n",
    "\n",
    "y = np.hstack(experiment_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129623, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 1.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  1.,  0., ...,  0.,  0.,  1.],\n",
       "         [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  1.,  0.]]],\n",
       "\n",
       "\n",
       "       [[[ 0.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "       [[[ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "         [ 1.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  1.,  0.,  1.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "       [[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  1.,  0., ...,  0.,  1.,  1.]]],\n",
       "\n",
       "\n",
       "       [[[ 1.,  0.,  1., ...,  0.,  1.,  1.],\n",
       "         [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  1.,  0., ...,  0.,  0.,  0.]]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True,  True, False],\n",
       "       [ True, False, False,  True],\n",
       "       [ True, False, False, False],\n",
       "       [ True,  True, False,  True],\n",
       "       [ True, False,  True, False]], dtype=bool)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_valid = 1000\n",
    "X_train = X[:-n_valid,:,:,:]\n",
    "y_train = y[:-n_valid,:]\n",
    "\n",
    "X_valid = X[-n_valid:,:,:,:]\n",
    "y_valid = y[-n_valid:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with the model used in the Dragonn tutorial. Train and plot the train and validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = models.SequenceDNN(\n",
    "    seq_length=X_train.shape[3],\n",
    "    num_filters=[1],\n",
    "    conv_width=[45],\n",
    "    pool_width=45,\n",
    "    num_tasks=y_train.shape[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.train(X_train, y_train, (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_loss(model):\n",
    "    train_losses, valid_losses = [np.array([epoch_metrics['Loss'] for epoch_metrics in metrics])\n",
    "                                  for metrics in (model.train_metrics, model.valid_metrics)]\n",
    "\n",
    "    # Pretty sure early stopping works by taking the mean of losses, might want to double check\n",
    "    train_losses = train_losses.mean(axis=1)\n",
    "    valid_losses = valid_losses.mean(axis=1)\n",
    "\n",
    "    f = plt.figure(figsize=(10, 4))\n",
    "    ax = f.add_subplot(1, 1, 1)\n",
    "    \n",
    "    ax.plot(range(len(train_losses)), train_losses, label='Training',lw=4)\n",
    "    ax.plot(range(len(train_losses)), valid_losses, label='Validation', lw=4)\n",
    "    \n",
    "    min_loss_indx = min(enumerate(valid_losses), key=lambda x: x[1])[0]\n",
    "    ax.plot([min_loss_indx, min_loss_indx], [0, 1.0], 'k--', label='Early Stop')\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_ylim((0.0,1.0))\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_loss(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test on a multi-filter model (not a lot of filters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "multi_filter_model = models.SequenceDNN(\n",
    "    seq_length=X_train.shape[3],\n",
    "    num_filters=[2],\n",
    "    conv_width=[45],\n",
    "    pool_width=45,\n",
    "    dropout=0.1,\n",
    "    num_tasks=y_train.shape[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "multi_filter_model.train(X_train, y_train, (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_loss(multi_filter_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
